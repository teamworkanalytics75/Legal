# ğŸ—ï¸ Background Agent System Architecture

## ğŸ“‹ Overview

The Background Agent System is a **continuously running, locally-hosted AI infrastructure** that processes legal documents and generates insights using open-source LLMs via Ollama.

**Key Characteristics:**
- âœ… **100% Local** - No cloud dependencies, complete privacy
- âœ… **Zero Cost** - Uses open-source models
- âœ… **Async/Concurrent** - Multiple agents run simultaneously
- âœ… **Fault Tolerant** - Checkpoint/resume, retry logic
- âœ… **Resource Aware** - Configurable RAM/CPU limits

---

## ğŸ¯ Design Principles

### 1. Separation of Concerns
- **Core Framework** - Task queue, agent base classes, orchestration
- **Agent Implementations** - Specific legal analysis agents
- **Configuration** - YAML-based, easily customizable

### 2. Asynchronous Processing
- All agents use `async/await` for efficiency
- Non-blocking I/O for file operations
- Concurrent task processing

### 3. Priority-Based Scheduling
- **HIGH** - Document monitoring (real-time)
- **MEDIUM** - Research and analysis (regular intervals)
- **LOW** - Heavy computations (periodic)

### 4. Checkpoint/Resume
- Agents save state periodically
- System can restart without losing work
- Task queue persists in SQLite

---

## ğŸ›ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AgentSystem (Orchestrator)                  â”‚
â”‚  - Loads configuration                                          â”‚
â”‚  - Manages agent lifecycle                                      â”‚
â”‚  - Schedules periodic tasks                                     â”‚
â”‚  - Monitors system resources                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   TaskQueue      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Background Agent â”‚
   â”‚   (SQLite DB)    â”‚          â”‚   (Base Class)   â”‚
   â”‚                  â”‚          â”‚                  â”‚
   â”‚ - Priority queue â”‚          â”‚ - async process()â”‚
   â”‚ - Status trackingâ”‚          â”‚ - LLM integrationâ”‚
   â”‚ - Retry logic    â”‚          â”‚ - Checkpointing  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                     â–¼                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ DocumentMonitorâ”‚    â”‚ LegalResearch  â”‚   â”‚ CitationNetworkâ”‚
         â”‚     Agent      â”‚    â”‚     Agent      â”‚   â”‚     Agent      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼                     â–¼                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚PatternDetectionâ”‚    â”‚Settlement      â”‚   â”‚  Custom Agent  â”‚
         â”‚     Agent      â”‚    â”‚   Optimizer    â”‚   â”‚  (Your Agent)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Ollama Server     â”‚
                              â”‚   (localhost:11434) â”‚
                              â”‚                     â”‚
                              â”‚ - llama3.2:7b       â”‚
                              â”‚ - phi3:medium       â”‚
                              â”‚ - mistral:13b       â”‚
                              â”‚ - codellama:7b      â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Component Details

### 1. AgentSystem (Orchestrator)

**File:** `background_agents/core/agent_system.py`

**Responsibilities:**
- Load and parse YAML configuration
- Register agents and initialize them
- Start task processing loops for each agent
- Schedule periodic tasks based on intervals
- Monitor system resources (RAM, CPU)
- Handle graceful shutdown

**Key Methods:**
```python
async def start()                      # Start the system
async def stop()                       # Stop the system
def register_agent(agent)              # Add agent to system
async def process_agent_tasks(name)    # Task processing loop
async def schedule_periodic_tasks()    # Scheduler loop
```

---

### 2. TaskQueue (SQLite-backed)

**File:** `background_agents/core/task_queue.py`

**Responsibilities:**
- Persist tasks to SQLite database
- Priority-based task retrieval
- Status tracking (pending â†’ in_progress â†’ completed/failed)
- Retry logic with exponential backoff
- Task statistics and reporting

**Database Schema:**
```sql
CREATE TABLE tasks (
    id TEXT PRIMARY KEY,
    agent_name TEXT NOT NULL,
    task_type TEXT NOT NULL,
    priority INTEGER NOT NULL,
    status TEXT NOT NULL,
    data TEXT NOT NULL,
    created_at TEXT NOT NULL,
    started_at TEXT,
    completed_at TEXT,
    result TEXT,
    error TEXT,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3
)
```

**Indexes:**
- `idx_status_priority` - For efficient task retrieval
- `idx_agent` - For agent-specific queries

---

### 3. BackgroundAgent (Base Class)

**File:** `background_agents/core/agent.py`

**Responsibilities:**
- Provide common agent interface
- Handle LLM queries via Ollama
- Manage agent lifecycle (init, shutdown)
- Track statistics (tasks, errors, success rate)
- Implement checkpoint/resume

**Abstract Method:**
```python
async def process(self, task: Any) -> Any:
    """Must be implemented by subclasses"""
```

**Key Methods:**
```python
async def llm_query(prompt, temperature, max_tokens)  # Query LLM
async def run_task(task)                              # Run with error handling
async def save_checkpoint(state)                      # Save state
async def load_checkpoint()                           # Restore state
def get_stats()                                       # Get agent stats
```

---

### 4. Agent Implementations

#### DocumentMonitorAgent
**File:** `background_agents/agents/document_monitor.py`

**Purpose:** Watch directories for new PDFs/docs and extract metadata

**Process Flow:**
1. Receive file path from task
2. Extract text (PyMuPDF for PDFs)
3. Use LLM to extract structured data:
   - Case name
   - Parties
   - Court/jurisdiction
   - Citations
   - Legal issues
4. Save as JSON

**Model:** `phi3:medium` (fast, efficient)

---

#### LegalResearchAgent
**File:** `background_agents/agents/legal_research.py`

**Purpose:** Generate research insights from case corpus

**Process Flow:**
1. Receive research request (summary, principles, trends)
2. Query LLM with relevant cases
3. Generate structured analysis
4. Save as Markdown

**Model:** `llama3.2:7b` (balanced reasoning)

---

#### CitationNetworkAgent
**File:** `background_agents/agents/citation_network.py`

**Purpose:** Build and analyze citation networks

**Process Flow:**
1. Extract citations from cases using LLM
2. Build NetworkX directed graph
3. Calculate PageRank and influence scores
4. Export as GEXF format for visualization

**Model:** `mistral:13b` (deep analysis)

**Dependencies:** `networkx`, `python-louvain`

---

#### PatternDetectionAgent
**File:** `background_agents/agents/pattern_detection.py`

**Purpose:** Identify patterns in case outcomes

**Process Flow:**
1. Analyze batch of cases (min 5)
2. Use LLM to identify patterns:
   - Success/failure factors
   - Jurisdictional patterns
   - Temporal trends
   - Factual patterns
3. Generate statistical observations
4. Save as JSON

**Model:** `llama3.2:7b` (statistical reasoning)

---

#### SettlementOptimizerAgent
**File:** `background_agents/agents/settlement_optimizer.py`

**Purpose:** Run Monte Carlo simulations for settlement analysis

**Process Flow:**
1. Extract case parameters (success prob, damages, costs)
2. Run 10K Monte Carlo iterations (NumPy)
3. Calculate EV, percentiles, risk-adjusted value
4. Generate settlement recommendation
5. Save as JSON

**Model:** None (deterministic, no LLM needed)

---

## ğŸ”„ Task Processing Flow

```
1. Scheduler creates periodic tasks
   â””â”€> Task.create(agent_name, data, priority)

2. TaskQueue.add_task(task)
   â””â”€> Insert into SQLite with status=pending

3. AgentSystem.process_agent_tasks(agent_name)
   â””â”€> Loop:
       â”œâ”€> Get next task from queue (priority order)
       â”œâ”€> Update status to in_progress
       â”œâ”€> Agent.run_task(task.data)
       â”‚   â”œâ”€> Call agent.process(task.data)
       â”‚   â”œâ”€> Handle errors
       â”‚   â””â”€> Return result
       â”œâ”€> Update status to completed/failed
       â””â”€> Save result to database

4. On error:
   â””â”€> If retry_count < max_retries:
       â””â”€> Increment retry_count, set status=pending
   â””â”€> Else:
       â””â”€> Set status=failed, save error
```

---

## ğŸ›ï¸ Configuration System

**File:** `background_agents/config.yaml`

**Structure:**
```yaml
system:
  max_ram_usage_gb: 16
  max_cpu_cores: 12
  log_level: INFO

agents:
  document_monitor:
    enabled: true
    priority: high
    interval_minutes: 5
    model: "phi3:medium"

  legal_research:
    enabled: true
    priority: medium
    interval_minutes: 30
    model: "llama3.2:7b"

monitored_directories:
  - path: "path/to/documents"
    watch_extensions: [".pdf", ".docx"]
    auto_process: true

ollama:
  host: "http://localhost:11434"
  timeout_seconds: 300

logging:
  directory: "background_agents/logs"
  max_file_size_mb: 10
```

---

## ğŸ”Œ Ollama Integration

### Connection
- Agents communicate with Ollama via HTTP API
- Default: `http://localhost:11434`
- Timeout: 300 seconds (configurable)

### Model Selection
Each agent can use a different model:
- **Fast extraction**: `phi3:medium` (~2GB RAM)
- **Balanced reasoning**: `llama3.2:7b` (~4GB RAM)
- **Deep analysis**: `mistral:13b` (~8GB RAM)
- **Code generation**: `codellama:7b` (~4GB RAM)

### Query Format
```python
response = ollama.generate(
    model="llama3.2:7b",
    prompt="Your prompt here",
    options={
        "temperature": 0.7,
        "num_predict": 2000,
    }
)
```

---

## ğŸ“Š Resource Management

### RAM Allocation
```
Total: 32GB
â”œâ”€ Windows + Apps: 8GB
â”œâ”€- Cursor/VS Code: 4GB
â”œâ”€- Chrome: 2GB
â””â”€- Background Agents: 16GB
    â”œâ”€- Ollama models: ~12GB (3-4 models loaded)
    â””â”€- Python processes: ~4GB
```

### CPU Usage
- Agents use async I/O (minimal blocking)
- CPU spikes only during LLM inference
- Average: 40-50% CPU usage
- Peak: 70-80% during heavy tasks

### Disk I/O
- Sequential writes to output files
- SQLite database (low I/O)
- Model cache on disk (one-time read)

---

## ğŸ›¡ï¸ Error Handling

### Retry Logic
```python
if task fails:
    if retry_count < max_retries (default: 3):
        retry_count += 1
        status = pending
        # Exponential backoff handled by queue
    else:
        status = failed
        save error message
```

### Checkpoint/Resume
```python
# Every 15 minutes (configurable)
agent.save_checkpoint({
    'processed_files': [...],
    'last_position': 123,
    'partial_results': {...}
})

# On restart
state = agent.load_checkpoint()
if state:
    resume_from(state)
```

### Graceful Shutdown
```python
# On Ctrl+C or SIGTERM
1. Set _running = False
2. Wait for current tasks to complete
3. Save checkpoints
4. Close Ollama connections
5. Flush logs
6. Exit cleanly
```

---

## ğŸ” Logging and Monitoring

### Log Files
```
background_agents/logs/
â”œâ”€ system.log          # Main system events
â”œâ”€ document_monitor.log
â”œâ”€ legal_research.log
â””â”€ ...
```

### Log Levels
- **DEBUG** - Detailed task information
- **INFO** - Task start/complete, agent status
- **WARNING** - Retries, performance issues
- **ERROR** - Task failures, exceptions

### Statistics
```python
system.get_system_stats()
# Returns:
{
    'running': True,
    'agents': {
        'document_monitor': {
            'running': False,
            'total_tasks': 45,
            'errors': 2,
            'success_rate': 0.956
        }
    },
    'queue': {
        'document_monitor': {
            'pending': 5,
            'in_progress': 1,
            'completed': 39,
            'failed': 2
        }
    }
}
```

---

## ğŸ§ª Testing Strategy

### Unit Tests
- Test each agent in isolation
- Mock Ollama responses
- Test error handling

### Integration Tests
- Test agent system with real Ollama
- Test task queue persistence
- Test concurrent processing

### Performance Tests
- Measure RAM usage over time
- Track CPU usage patterns
- Benchmark task throughput

---

## ğŸš€ Deployment Options

### Option 1: Terminal (Development)
```bash
python background_agents/start_agents.py
```

### Option 2: Windows Service (Production)
```powershell
nssm install TheMatrixAgents python start_agents.py
net start TheMatrixAgents
```

### Option 3: Docker (Future)
```dockerfile
FROM python:3.11
RUN curl -fsSL https://ollama.com/install.sh | sh
COPY . /app
CMD ["python", "background_agents/start_agents.py"]
```

---

## ğŸ”„ Extensibility

### Adding a Custom Agent

```python
from background_agents.core import BackgroundAgent, AgentConfig

class MyCustomAgent(BackgroundAgent):
    def __init__(self, config: AgentConfig):
        super().__init__(config)
        self.output_dir = Path("background_agents/outputs/my_agent")
        self.output_dir.mkdir(parents=True, exist_ok=True)

    async def process(self, task: Any) -> Any:
        # Your custom logic
        data = task['input_data']

        # Use LLM if needed
        result = await self.llm_query(
            prompt=f"Analyze: {data}",
            temperature=0.7
        )

        # Save output
        output_file = self.output_dir / f"result_{datetime.now()}.json"
        with open(output_file, 'w') as f:
            json.dump({'result': result}, f)

        return result

# Register in config.yaml
agents:
  my_custom_agent:
    enabled: true
    priority: medium
    interval_minutes: 60
    model: "llama3.2:7b"

# Register in start_agents.py
system.register_agent(MyCustomAgent(agent_config))
```

---

## ğŸ“ˆ Performance Characteristics

### Throughput
- **Documents**: 30-60 seconds per PDF
- **Summaries**: 2-3 minutes per case
- **Networks**: 10-15 minutes per 100 cases
- **Patterns**: 5-10 minutes per 50 cases

### Scalability
- **Linear scaling** with more RAM
- **Parallelizable** across multiple GPUs
- **Horizontal scaling** via distributed queue

### Bottlenecks
1. **LLM inference** (70% of time)
2. **PDF extraction** (20% of time)
3. **I/O operations** (10% of time)

---

## ğŸ“ Design Patterns Used

1. **Factory Pattern** - Agent creation
2. **Observer Pattern** - Task notifications
3. **Strategy Pattern** - Different agent behaviors
4. **Template Method** - Base agent class
5. **Command Pattern** - Task encapsulation
6. **Repository Pattern** - TaskQueue persistence

---

## ğŸ“š Further Reading

- **Ollama Docs**: https://ollama.com/docs
- **AsyncIO Guide**: https://docs.python.org/3/library/asyncio.html
- **NetworkX**: https://networkx.org/documentation/
- **SQLite**: https://www.sqlite.org/docs.html

---

**Status:** âœ… Production Ready
**Version:** 1.0.0
**Last Updated:** October 21, 2025

